{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 02:35:37.446143: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-09 02:35:37.446599: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-09 02:35:37.448412: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-09 02:35:37.454044: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-09 02:35:37.463804: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-09 02:35:37.466729: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-09 02:35:37.473847: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-09 02:35:37.977909: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In 1974, the teenager Martha Moxley (Maggie Gr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OK... so... I really like Kris Kristofferson a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>***SPOILER*** Do not read this, if you think a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi for all the people who have seen this wonde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I recently bought the DVD, forgetting just how...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>OK, lets start with the best. the building. al...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>The British 'heritage film' industry is out of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I don't even know where to begin on this one. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>Richard Tyler is a little boy who is scared of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>I waited long to watch this movie. Also becaus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "0      In 1974, the teenager Martha Moxley (Maggie Gr...          1\n",
       "1      OK... so... I really like Kris Kristofferson a...          0\n",
       "2      ***SPOILER*** Do not read this, if you think a...          0\n",
       "3      hi for all the people who have seen this wonde...          1\n",
       "4      I recently bought the DVD, forgetting just how...          0\n",
       "...                                                  ...        ...\n",
       "49995  OK, lets start with the best. the building. al...          0\n",
       "49996  The British 'heritage film' industry is out of...          0\n",
       "49997  I don't even know where to begin on this one. ...          0\n",
       "49998  Richard Tyler is a little boy who is scared of...          0\n",
       "49999  I waited long to watch this movie. Also becaus...          1\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import Counter\n",
    "df = pd.read_csv('../datasets/movie_data.csv', encoding='utf-8')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'In 1974, the teenager Martha Moxley (Maggie Grace)' 1\n",
      "b'OK... so... I really like Kris Kristofferson and h' 0\n",
      "b'***SPOILER*** Do not read this, if you think about' 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1723138538.843931  283543 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-09 02:35:38.844178: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-08-09 02:35:38.902422: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 객체 생성\n",
    "target = df.pop('sentiment')\n",
    "ds_raw = tf.data.Dataset.from_tensor_slices((df.values, target.values))\n",
    "\n",
    "# 데이터셋 확인\n",
    "for ex in ds_raw.take(3):\n",
    "    tf.print(ex[0].numpy()[0][:50], ex[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Alright, let me break it down for ya... Haggard is' 1\n",
      "b'I was impressed by the beautiful photography in th' 1\n",
      "b\"I've just watched Fingersmith, and I'm stunned to \" 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 02:35:38.960146: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "ds_raw = ds_raw.shuffle(target.shape[0], reshuffle_each_iteration=False)\n",
    "\n",
    "ds_raw = ds_raw.take(100)\n",
    "for ex in ds_raw.take(3):\n",
    "    tf.print(ex[0].numpy()[0][:50], ex[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import myprocess  # 'myprocess.py' 파일을 import합니다.\n",
    "\n",
    "preprocessor = myprocess.PreProcess(ds_raw, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "\n",
    "train_data, valid_data, test_data = preprocessor.get_datas(batch_size, train_size=0.4, valid_size = 0.1, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ex in ds_train.shuffle(10).take(5):\n",
    "#     print('sequence length', ex[0].shape)\n",
    "\n",
    "# print('어휘 사전 크기', len(preprocessor.token_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(preprocessor.token_counts)+ 2  # 예시를 위해 설정한 값, 실제 vocab_size에 맞게 변경 필요\n",
    "node_nums = [5, 10, 15]\n",
    "embedding_dims = [20, 40]\n",
    "layer_nums = [1, 2]\n",
    "\n",
    "model_list= myprocess.make_models(vocab_size, node_nums, embedding_dims, layer_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Summary:\n",
      "Model 2 Summary:\n",
      "Model 3 Summary:\n",
      "Model 4 Summary:\n",
      "Model 5 Summary:\n",
      "Model 6 Summary:\n",
      "Model 7 Summary:\n",
      "Model 8 Summary:\n",
      "Model 9 Summary:\n",
      "Model 10 Summary:\n",
      "Model 11 Summary:\n",
      "Model 12 Summary:\n",
      "Model 13 Summary:\n",
      "Model 14 Summary:\n",
      "Model 15 Summary:\n",
      "Model 16 Summary:\n",
      "Model 17 Summary:\n",
      "Model 18 Summary:\n",
      "Model 19 Summary:\n",
      "Model 20 Summary:\n",
      "Model 21 Summary:\n",
      "Model 22 Summary:\n",
      "Model 23 Summary:\n",
      "Model 24 Summary:\n",
      "Model 25 Summary:\n",
      "Model 26 Summary:\n",
      "Model 27 Summary:\n"
     ]
    }
   ],
   "source": [
    "for i, model in enumerate(model_list):\n",
    "    print(f\"Model {i+1} Summary:\")\n",
    "    # model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - accuracy: 0.5950 - loss: 0.6922 - val_accuracy: 0.6000 - val_loss: 0.6814\n",
      "Epoch 2/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.5950 - loss: 0.6828 - val_accuracy: 0.6000 - val_loss: 0.6748\n",
      "Epoch 3/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.5950 - loss: 0.6758 - val_accuracy: 0.6000 - val_loss: 0.6676\n",
      "Epoch 4/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5950 - loss: 0.6681 - val_accuracy: 0.6000 - val_loss: 0.6589\n",
      "Epoch 5/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.5950 - loss: 0.6587 - val_accuracy: 0.6000 - val_loss: 0.6482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=h5\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6100 - loss: 0.6487\n",
      "Epoch 1/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - accuracy: 0.5536 - loss: 0.6928 - val_accuracy: 0.6000 - val_loss: 0.6902\n",
      "Epoch 2/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.5950 - loss: 0.6907 - val_accuracy: 0.6000 - val_loss: 0.6866\n",
      "Epoch 3/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5950 - loss: 0.6875 - val_accuracy: 0.6000 - val_loss: 0.6826\n",
      "Epoch 4/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.5950 - loss: 0.6831 - val_accuracy: 0.6000 - val_loss: 0.6772\n",
      "Epoch 5/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5950 - loss: 0.6769 - val_accuracy: 0.6000 - val_loss: 0.6655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=h5\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6100 - loss: 0.6662\n",
      "Epoch 1/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - accuracy: 0.5950 - loss: 0.6930 - val_accuracy: 0.6000 - val_loss: 0.6916\n",
      "Epoch 2/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5950 - loss: 0.6917 - val_accuracy: 0.6000 - val_loss: 0.6904\n",
      "Epoch 3/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5950 - loss: 0.6905 - val_accuracy: 0.6000 - val_loss: 0.6891\n",
      "Epoch 4/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.5950 - loss: 0.6892 - val_accuracy: 0.6000 - val_loss: 0.6875\n",
      "Epoch 5/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5950 - loss: 0.6877 - val_accuracy: 0.6000 - val_loss: 0.6856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=h5\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6100 - loss: 0.6855\n",
      "Epoch 1/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.4631 - loss: 0.6946 - val_accuracy: 0.6000 - val_loss: 0.6925\n",
      "Epoch 2/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5950 - loss: 0.6906 - val_accuracy: 0.6000 - val_loss: 0.6891\n",
      "Epoch 3/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.5950 - loss: 0.6869 - val_accuracy: 0.6000 - val_loss: 0.6860\n",
      "Epoch 4/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5950 - loss: 0.6830 - val_accuracy: 0.6000 - val_loss: 0.6826\n",
      "Epoch 5/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.5950 - loss: 0.6789 - val_accuracy: 0.6000 - val_loss: 0.6779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=h5\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6100 - loss: 0.6740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([{'accuracy': [0.5600000023841858,\n",
       "    0.5600000023841858,\n",
       "    0.5600000023841858,\n",
       "    0.5600000023841858,\n",
       "    0.5600000023841858],\n",
       "   'loss': [0.6943395733833313,\n",
       "    0.6866958737373352,\n",
       "    0.6797022223472595,\n",
       "    0.6714575886726379,\n",
       "    0.6614041328430176],\n",
       "   'val_accuracy': [0.6000000238418579,\n",
       "    0.6000000238418579,\n",
       "    0.6000000238418579,\n",
       "    0.6000000238418579,\n",
       "    0.6000000238418579],\n",
       "   'val_loss': [0.6813910603523254,\n",
       "    0.6747540235519409,\n",
       "    0.6675747036933899,\n",
       "    0.6588791012763977,\n",
       "    0.648232102394104]},\n",
       "  {'accuracy': [0.5400000214576721,\n",
       "    0.5600000023841858,\n",
       "    0.5600000023841858,\n",
       "    0.5600000023841858,\n",
       "    0.5600000023841858],\n",
       "   'loss': [0.692973792552948,\n",
       "    0.6912850737571716,\n",
       "    0.6883357167243958,\n",
       "    0.6839531064033508,\n",
       "    0.678098738193512],\n",
       "   'val_accuracy': [0.6000000238418579,\n",
       "    0.6000000238418579,\n",
       "    0.6000000238418579,\n",
       "    0.6000000238418579,\n",
       "    0.6000000238418579],\n",
       "   'val_loss': [0.6902070045471191,\n",
       "    0.6865905523300171,\n",
       "    0.6826066970825195,\n",
       "    0.6771808862686157,\n",
       "    0.665532648563385]},\n",
       "  {'accuracy': [0.5600000023841858,\n",
       "    0.5600000023841858,\n",
       "    0.5600000023841858,\n",
       "    0.5600000023841858,\n",
       "    0.5600000023841858],\n",
       "   'loss': [0.6932135820388794,\n",
       "    0.6921827793121338,\n",
       "    0.6912460327148438,\n",
       "    0.6901640892028809,\n",
       "    0.6888044476509094],\n",
       "   'val_accuracy': [0.6000000238418579,\n",
       "    0.6000000238418579,\n",
       "    0.6000000238418579,\n",
       "    0.6000000238418579,\n",
       "    0.6000000238418579],\n",
       "   'val_loss': [0.6915770769119263,\n",
       "    0.6903890371322632,\n",
       "    0.6890909075737,\n",
       "    0.6875007748603821,\n",
       "    0.6855775713920593]},\n",
       "  {'accuracy': [0.46000000834465027,\n",
       "    0.5600000023841858,\n",
       "    0.5600000023841858,\n",
       "    0.5600000023841858,\n",
       "    0.5600000023841858],\n",
       "   'loss': [0.6947680711746216,\n",
       "    0.6914106011390686,\n",
       "    0.688137412071228,\n",
       "    0.6839765310287476,\n",
       "    0.6793198585510254],\n",
       "   'val_accuracy': [0.6000000238418579,\n",
       "    0.6000000238418579,\n",
       "    0.6000000238418579,\n",
       "    0.6000000238418579,\n",
       "    0.6000000238418579],\n",
       "   'val_loss': [0.6925331354141235,\n",
       "    0.689080536365509,\n",
       "    0.6859623193740845,\n",
       "    0.6826168298721313,\n",
       "    0.6778519749641418]}],\n",
       " [[0.649958074092865, 0.6000000238418579],\n",
       "  [0.6679009199142456, 0.6000000238418579],\n",
       "  [0.6860424280166626, 0.6000000238418579],\n",
       "  [0.6732802391052246, 0.6000000238418579]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myprocess.compile_train_save(model_list[:4], 5, train_data, valid_data, test_data  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Sequential name=sequential, built=True>,\n",
       " <Sequential name=sequential_1, built=True>,\n",
       " <Sequential name=sequential_2, built=True>,\n",
       " <Sequential name=sequential_3, built=True>,\n",
       " <Sequential name=sequential_4, built=False>,\n",
       " <Sequential name=sequential_5, built=False>,\n",
       " <Sequential name=sequential_6, built=False>,\n",
       " <Sequential name=sequential_7, built=False>,\n",
       " <Sequential name=sequential_8, built=False>,\n",
       " <Sequential name=sequential_9, built=False>,\n",
       " <Sequential name=sequential_10, built=False>,\n",
       " <Sequential name=sequential_11, built=False>,\n",
       " <Sequential name=sequential_12, built=False>,\n",
       " <Sequential name=sequential_13, built=False>,\n",
       " <Sequential name=sequential_14, built=False>,\n",
       " <Sequential name=sequential_15, built=False>,\n",
       " <Sequential name=sequential_16, built=False>,\n",
       " <Sequential name=sequential_17, built=False>,\n",
       " <Sequential name=sequential_18, built=False>,\n",
       " <Sequential name=sequential_19, built=False>,\n",
       " <Sequential name=sequential_20, built=False>,\n",
       " <Sequential name=sequential_21, built=False>,\n",
       " <Sequential name=sequential_22, built=False>,\n",
       " <Sequential name=sequential_23, built=False>,\n",
       " <Sequential name=sequential_24, built=False>,\n",
       " <Sequential name=sequential_25, built=False>,\n",
       " <Sequential name=sequential_26, built=False>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6100 - loss: 0.6487\n",
      "test accuracy : 60.00%\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6100 - loss: 0.6662\n",
      "test accuracy : 60.00%\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6100 - loss: 0.6855\n",
      "test accuracy : 60.00%\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6100 - loss: 0.6740\n",
      "test accuracy : 60.00%\n"
     ]
    }
   ],
   "source": [
    "for model in model_list[:4]:\n",
    "    test_results = model.evaluate(test_data)\n",
    "    print('test accuracy : {:.2f}%'. format(test_results[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model_list = myprocess.load_models_from_files(num_models=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6100 - loss: 0.6487 \n",
      "test accuracy : 60.00%\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6100 - loss: 0.6662\n",
      "test accuracy : 60.00%\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6100 - loss: 0.6855 \n",
      "test accuracy : 60.00%\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6100 - loss: 0.6740 \n",
      "test accuracy : 60.00%\n"
     ]
    }
   ],
   "source": [
    "for model in model_list:\n",
    "    test_results = model.evaluate(test_data)\n",
    "    print('test accuracy : {:.2f}%'. format(test_results[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = myprocess.majority_vote_ensemble(model_list, test_data, accuracy=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
