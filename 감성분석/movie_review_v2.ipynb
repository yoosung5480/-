{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In 1974, the teenager Martha Moxley (Maggie Gr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OK... so... I really like Kris Kristofferson a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>***SPOILER*** Do not read this, if you think a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi for all the people who have seen this wonde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I recently bought the DVD, forgetting just how...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>OK, lets start with the best. the building. al...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>The British 'heritage film' industry is out of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I don't even know where to begin on this one. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>Richard Tyler is a little boy who is scared of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>I waited long to watch this movie. Also becaus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "0      In 1974, the teenager Martha Moxley (Maggie Gr...          1\n",
       "1      OK... so... I really like Kris Kristofferson a...          0\n",
       "2      ***SPOILER*** Do not read this, if you think a...          0\n",
       "3      hi for all the people who have seen this wonde...          1\n",
       "4      I recently bought the DVD, forgetting just how...          0\n",
       "...                                                  ...        ...\n",
       "49995  OK, lets start with the best. the building. al...          0\n",
       "49996  The British 'heritage film' industry is out of...          0\n",
       "49997  I don't even know where to begin on this one. ...          0\n",
       "49998  Richard Tyler is a little boy who is scared of...          0\n",
       "49999  I waited long to watch this movie. Also becaus...          1\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv('../datasets/movie_data.csv', encoding='utf-8')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**전처리 단계**\n",
    "\n",
    "1. 데이테셋 객체만들고 이를 훈련, 테스트, 검증 데이터셋으로 나눈다.\n",
    "2. 훈련 데이터셋에 있는 고유한 단어를 찾는다.\n",
    "3. 고유한 단어를 고유한 저우로 매핑하고 리뷰 텍스트를 정수 배열로 인코딩한다.\n",
    "4. 모델에 입력하기 위해 데이터셋을 미니 배치로 나눈다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'In 1974, the teenager Martha Moxley (Maggie Grace)' 1\n",
      "b'OK... so... I really like Kris Kristofferson and h' 0\n",
      "b'***SPOILER*** Do not read this, if you think about' 0\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 객체 생성\n",
    "target = df.pop('sentiment')\n",
    "ds_raw = tf.data.Dataset.from_tensor_slices((df.values, target.values))\n",
    "\n",
    "# 데이터셋 확인\n",
    "for ex in ds_raw.take(3):\n",
    "    tf.print(ex[0].numpy()[0][:50], ex[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 샘플의 개수는 5만 개의 샘플이다.\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*데이터셋 분리*\n",
    "(총 5만개)\n",
    "- 25000개 : 홀드아웃 테스트 데이터셋\n",
    "- 20000개 : 훈련용 테스트 데이터셋\n",
    "- 5000개 : 샘플 검증용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "ds_raw = ds_raw.shuffle(target.shape[0], reshuffle_each_iteration=False)\n",
    "ds_raw_test = ds_raw.take(25000)\n",
    "ds_raw_train = ds_raw.take(20000)\n",
    "ds_raw_valid = ds_raw.take(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*데이터셋 인코딩*\n",
    "* 훈련 데이터셋에서 고유한 단어를 찾는다 -> 숫자로 문자열을 인코딩해야한다.\n",
    "* 파이썬 표준 라이브러리에 있는 collections패키지의 Counter 클래스를 사용해한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어휘 사전 크기 87519\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# 고유 토큰을 수집하는 코드이다.\n",
    "tokenizer = tfds.deprecated.text.Tokenizer()\n",
    "token_counts = Counter()\n",
    "for ex in ds_raw_train:\n",
    "    tokens = tokenizer.tokenize(ex[0].numpy()[0])\n",
    "    token_counts.update(tokens)\n",
    "\n",
    "print('어휘 사전 크기', len(token_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[95, 10, 170, 4070]\n"
     ]
    }
   ],
   "source": [
    "# 고유 토큰을 정수로 인코딩하기\n",
    "encoder = tfds.deprecated.text.TokenTextEncoder(token_counts)\n",
    "example_str = 'this is an example!'\n",
    "print(encoder.encode(example_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 변환 인코딩 함수 정의 (텍스트_텐서)\n",
    "def encode(text_tensor, label):\n",
    "    text = text_tensor.numpy()[0]\n",
    "    encoded_text = encoder.encode(text)\n",
    "    return encoded_text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수를 TF연산으로 변환하기\n",
    "def encode_map_fn(text, label):\n",
    "    return tf.py_function(encode, inp=[text, label], Tout=(tf.int64, tf.int64))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence length (161,)\n",
      "sequence length (327,)\n",
      "sequence length (137,)\n",
      "sequence length (50,)\n",
      "sequence length (34,)\n"
     ]
    }
   ],
   "source": [
    "# 텐서플로 연산을 통해서 데이터셋을 정수리스트로 인코딩했다.\n",
    "ds_train = ds_raw_train.map(encode_map_fn)\n",
    "ds_valid = ds_raw_valid.map(encode_map_fn)\n",
    "ds_test = ds_raw_test.map(encode_map_fn)\n",
    "\n",
    "# ds_train 에서 인코딩된 정수시퀀스 길이 예시 5개 출력\n",
    "tf.random.set_seed(1)\n",
    "for ex in ds_train.shuffle(1000).take(5):\n",
    "    print('sequence length', ex[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**문자열 들의 인코딩된 정수 시퀀스 길이가 다르다! (마치, 샘플간의 특성의 개수가 다른상황과 유사하다.)**\n",
    "- padded_batch()메서드를 이용해서 하나의 배치에 포함되는 모든 원소를 자동으로 0으로 패딩해서 모든 시퀀스가 동일한 길이가 되도록 한다!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size (114,)\n",
      "sample size (226,)\n",
      "sample size (162,)\n",
      "sample size (83,)\n",
      "sample size (171,)\n",
      "sample size (61,)\n",
      "sample size (308,)\n",
      "sample size (413,)\n",
      "to batch case size (4, 226)\n",
      "to batch case size (4, 413)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 17:16:39.868557: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# 적용 예시\n",
    "ds_subset = ds_train.take(8)\n",
    "for ex in ds_subset:\n",
    "    print('sample size', ex[0].shape)\n",
    "\n",
    "ds_batched = ds_subset.padded_batch(4, padded_shapes=([-1], []))\n",
    "for batch in ds_batched:\n",
    "    print('to batch case size', batch[0].shape)\n",
    "\n",
    "#이는 첫번째 4개짜리 배치에서는 226의 크기가 젤 크니깐 226 크기로 0으로 패딩한 결과.\n",
    "#두번째 4개짜리 배치에서는 413이 가장크니깐 413 크기로 0으로 패딩한 결과."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 데이터셋의 배치 크기를 32의 미니 배치로 나눈다.\n",
    "train_data = ds_train.padded_batch(32, padded_shapes=([-1], []))\n",
    "vaild_data = ds_valid.padded_batch(32, padded_shapes=([-1], []))\n",
    "test_data = ds_test.padded_batch(32, padded_shapes=([-1], []))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 차원의 저주, 특성 희소성 문제 ##\n",
    "* 고유한 단어의 수는 수만, 수십만 규모가 될수있다. -> 수십만 차원의 특성을 훈련시켜야하는 경우가 생긴다.\n",
    "* 또 하나를 제외하고 모든 원소가 0임으로 특성 벡터가 매우 희소해진다.\n",
    "\n",
    "## 임베딩으로 문제해결 ##\n",
    "** 임베딩이랑? **\n",
    "* 임베딩은 원-핫 인코딩과 달리 고정된 길이의 벡터를 사용하여 무한히 많은 실수 표현 (예를들어 [-1. 1])\n",
    "- *장점*\n",
    "- 특성 공간 차원축소 -> 차원의 저주 해소\n",
    "- 임베딩층의 최적화로 중요한 특성 추출이 원핫 인코딩보다 용이하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embed-layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embed-layer (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m6\u001b[0m)          │           \u001b[38;5;34m600\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> (2.34 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m600\u001b[0m (2.34 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> (2.34 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m600\u001b[0m (2.34 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "# 임베딩 모델 생성 예시.\n",
    "model = tf.keras.Sequential()           # 이 임베딩 행렬의 크기는 100 x 6 이다.\n",
    "model.add(Embedding(input_dim=100,      # 모델이 처리할 단어의 개수, 어휘의 크기\n",
    "                    output_dim = 6,     # 임베딩 행렬의 차원수\n",
    "                    input_length=20,\n",
    "                    name='embed-layer'))\n",
    "model.build(input_shape=(None, 20))\n",
    "model.summary() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
