{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 06:52:13.758198: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-09 06:52:13.758693: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-09 06:52:13.760828: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-09 06:52:13.766764: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-09 06:52:13.777062: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-09 06:52:13.779757: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-09 06:52:13.787181: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-09 06:52:14.352705: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import chardet\n",
    "import os\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 경로\n",
    "file_path = '/home/jys0714/바탕화면/-/datasets/McDonald_s_Reviews.csv'\n",
    "\n",
    "# 파일 인코딩 확인 및 데이터 로드\n",
    "\n",
    "df = pd.read_csv(file_path, encoding='latin1')\n",
    "df = df.dropna()\n",
    "\n",
    "# df = df.head(100)\n",
    "\n",
    "# # 데이터셋의 첫 몇 행 출력\n",
    "# print(df.head())\n",
    "\n",
    "# # 데이터셋 정보 출력\n",
    "# print(df.info())\n",
    "\n",
    "# # 리뷰 컬럼의 샘플 데이터 출력\n",
    "# print(df['review'].sample(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특수 문자를 제거하는 함수 정의\n",
    "def remove_invalid_chars(text):\n",
    "    return re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "\n",
    "# review 컬럼에서 특수 문자 제거\n",
    "df['review'] = df['review'].apply(remove_invalid_chars)\n",
    "\n",
    "\n",
    "# 필요한 열들만 선택\n",
    "X = df[['store_address', 'latitude ', 'longitude', 'rating_count', 'review_time']]\n",
    "review = df['review']\n",
    "target = df['rating'].astype(str).str[0].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        1\n",
       "2        0\n",
       "3        1\n",
       "4        0\n",
       "        ..\n",
       "33391    0\n",
       "33392    1\n",
       "33393    1\n",
       "33394    1\n",
       "33395    1\n",
       "Name: rating, Length: 32736, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rate_categorize(rate):\n",
    "    if rate > 3:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "target = target.apply(rate_categorize)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# 원-핫 인코딩할 열들 선택\n",
    "categorical_columns = ['store_address', 'latitude ', 'longitude', 'review_time']\n",
    "\n",
    "# 원-핫 인코딩 수행\n",
    "one_hot_encoder = OneHotEncoder(sparse_output =False)\n",
    "one_hot_encoded = one_hot_encoder.fit_transform(df[categorical_columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import myprocess\n",
    "\n",
    "padded_sequences, token_counts = myprocess.preprocessing_tokinize(review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1723153941.416311  309369 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-09 06:52:21.416531: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# 텐서로 변환\n",
    "review_tensor = tf.convert_to_tensor(padded_sequences, dtype=tf.float64)\n",
    "one_hot_tensor = tf.convert_to_tensor(one_hot_encoded, dtype=tf.float64)\n",
    "target_tensor = tf.convert_to_tensor(target.values, dtype=tf.float64)\n",
    "combined_features = tf.concat([review_tensor, one_hot_tensor], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0] 0\n",
      "[0 0 0 ... 0 0 0] 1\n",
      "[0 0 0 ... 0 0 0] 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 06:52:22.961017: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow 데이터셋으로 변환\n",
    "combined_ds = tf.data.Dataset.from_tensor_slices((combined_features, target_tensor))\n",
    "\n",
    "# 결합된 데이터셋의 샘플 확인\n",
    "for features, label in combined_ds.take(3):\n",
    "    tf.print(features[:10], label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14095"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process = myprocess.PreProcess(combined_ds, target.shape[0], is_tokenize=True)\n",
    "len(token_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_data, valid_data, test_data = process.get_datas(batch_size, train_size=0.4, valid_size = 0.1, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoded.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Sequential name=sequential, built=False>,\n",
       " <Sequential name=sequential_1, built=False>,\n",
       " <Sequential name=sequential_2, built=False>,\n",
       " <Sequential name=sequential_3, built=False>,\n",
       " <Sequential name=sequential_4, built=False>,\n",
       " <Sequential name=sequential_5, built=False>,\n",
       " <Sequential name=sequential_6, built=False>,\n",
       " <Sequential name=sequential_7, built=False>,\n",
       " <Sequential name=sequential_8, built=False>,\n",
       " <Sequential name=sequential_9, built=False>,\n",
       " <Sequential name=sequential_10, built=False>,\n",
       " <Sequential name=sequential_11, built=False>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(token_counts) + one_hot_encoded.shape[1] + 2  \n",
    "node_nums = [32, 64]\n",
    "embedding_dims = [75, 100, 125]\n",
    "layer_nums = [1, 2]\n",
    "\n",
    "model_list= myprocess.make_models(vocab_size, node_nums, embedding_dims, layer_nums)\n",
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - accuracy: 0.5312 - loss: 0.6827 - val_accuracy: 0.6728 - val_loss: 0.6282\n",
      "Epoch 2/10\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 38ms/step - accuracy: 0.6631 - loss: 0.6328 - val_accuracy: 0.6541 - val_loss: 0.6246\n",
      "Epoch 3/10\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 37ms/step - accuracy: 0.6541 - loss: 0.6263 - val_accuracy: 0.6651 - val_loss: 0.6140\n",
      "Epoch 4/10\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 38ms/step - accuracy: 0.6602 - loss: 0.6137 - val_accuracy: 0.7039 - val_loss: 0.5847\n",
      "Epoch 5/10\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 38ms/step - accuracy: 0.6726 - loss: 0.6036 - val_accuracy: 0.5176 - val_loss: 0.6920\n",
      "Epoch 6/10\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 37ms/step - accuracy: 0.5176 - loss: 0.6869 - val_accuracy: 0.5203 - val_loss: 0.6745\n",
      "Epoch 7/10\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 37ms/step - accuracy: 0.5228 - loss: 0.6761 - val_accuracy: 0.8097 - val_loss: 0.4562\n",
      "Epoch 8/10\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 37ms/step - accuracy: 0.8371 - loss: 0.3924 - val_accuracy: 0.9001 - val_loss: 0.2531\n",
      "Epoch 9/10\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 37ms/step - accuracy: 0.9021 - loss: 0.2513 - val_accuracy: 0.9221 - val_loss: 0.1951\n",
      "Epoch 10/10\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 38ms/step - accuracy: 0.9256 - loss: 0.1946 - val_accuracy: 0.9395 - val_loss: 0.1520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=h5\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9436 - loss: 0.1496\n",
      "Epoch 1/10\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 38ms/step - accuracy: 0.5022 - loss: 0.6952 - val_accuracy: 0.5176 - val_loss: 0.6858\n",
      "Epoch 2/10\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 38ms/step - accuracy: 0.5067 - loss: 0.6854 - val_accuracy: 0.5176 - val_loss: 0.6769\n",
      "Epoch 3/10\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 38ms/step - accuracy: 0.5402 - loss: 0.6752 - val_accuracy: 0.5197 - val_loss: 0.6767\n",
      "Epoch 4/10\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 38ms/step - accuracy: 0.5238 - loss: 0.6750 - val_accuracy: 0.6685 - val_loss: 0.6200\n",
      "Epoch 5/10\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 37ms/step - accuracy: 0.6607 - loss: 0.6250 - val_accuracy: 0.6737 - val_loss: 0.6134\n",
      "Epoch 6/10\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - accuracy: 0.6708 - loss: 0.6103 - val_accuracy: 0.7482 - val_loss: 0.5104\n",
      "Epoch 7/10\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 36ms/step - accuracy: 0.7579 - loss: 0.5005 - val_accuracy: 0.8191 - val_loss: 0.4133\n",
      "Epoch 8/10\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 36ms/step - accuracy: 0.8316 - loss: 0.3972 - val_accuracy: 0.8723 - val_loss: 0.3293\n",
      "Epoch 9/10\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 36ms/step - accuracy: 0.8597 - loss: 0.3433 - val_accuracy: 0.8607 - val_loss: 0.3377\n",
      "Epoch 10/10\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 37ms/step - accuracy: 0.8604 - loss: 0.3336 - val_accuracy: 0.8753 - val_loss: 0.3019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=h5\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.8759 - loss: 0.3000\n",
      "Epoch 1/10\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 37ms/step - accuracy: 0.5067 - loss: 0.6902 - val_accuracy: 0.5225 - val_loss: 0.6792\n",
      "Epoch 2/10\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 37ms/step - accuracy: 0.6537 - loss: 0.5595 - val_accuracy: 0.8753 - val_loss: 0.2960\n",
      "Epoch 3/10\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 37ms/step - accuracy: 0.8910 - loss: 0.2704 - val_accuracy: 0.9233 - val_loss: 0.2031\n",
      "Epoch 4/10\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 37ms/step - accuracy: 0.9284 - loss: 0.1955 - val_accuracy: 0.9404 - val_loss: 0.1525\n",
      "Epoch 5/10\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 37ms/step - accuracy: 0.9494 - loss: 0.1454 - val_accuracy: 0.9499 - val_loss: 0.1276\n",
      "Epoch 6/10\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.9607 - loss: 0.1173 - val_accuracy: 0.9584 - val_loss: 0.1071\n",
      "Epoch 7/10\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 38ms/step - accuracy: 0.9624 - loss: 0.1098 - val_accuracy: 0.9649 - val_loss: 0.1001\n",
      "Epoch 8/10\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 37ms/step - accuracy: 0.9682 - loss: 0.0982 - val_accuracy: 0.9698 - val_loss: 0.0854\n",
      "Epoch 9/10\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 0.9684 - loss: 0.0887 - val_accuracy: 0.9743 - val_loss: 0.0734\n",
      "Epoch 10/10\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 37ms/step - accuracy: 0.9750 - loss: 0.0764 - val_accuracy: 0.9749 - val_loss: 0.0723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=h5\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9754 - loss: 0.0725\n",
      "Epoch 1/10\n",
      "\u001b[1m288/512\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - accuracy: 0.4997 - loss: 0.6922"
     ]
    }
   ],
   "source": [
    "myprocess.compile_train_save(model_list, 10, train_data, valid_data, test_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Sequential name=sequential, built=True>,\n",
       " <Sequential name=sequential_1, built=True>,\n",
       " <Sequential name=sequential_2, built=True>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list = myprocess.load_models_from_files(num_models=3)\n",
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9436 - loss: 0.1496\n",
      "test accuracy : 94.79%\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8759 - loss: 0.3000\n",
      "test accuracy : 87.73%\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9754 - loss: 0.0725\n",
      "test accuracy : 97.66%\n"
     ]
    }
   ],
   "source": [
    "for model in model_list:\n",
    "    test_results = model.evaluate(test_data)\n",
    "    print('test accuracy : {:.2f}%'. format(test_results[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = myprocess.majority_vote_ensemble(model_list, test_data, accuracy=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (410,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m         targets\u001b[38;5;241m.\u001b[39mappend(label\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(targets)\n\u001b[0;32m---> 11\u001b[0m test_labels \u001b[38;5;241m=\u001b[39m \u001b[43mextract_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m test_labels\n",
      "Cell \u001b[0;32mIn[109], line 9\u001b[0m, in \u001b[0;36mextract_target\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, label \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[1;32m      8\u001b[0m     targets\u001b[38;5;241m.\u001b[39mappend(label\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (410,) + inhomogeneous part."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
