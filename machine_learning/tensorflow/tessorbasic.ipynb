{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
      "tf.Tensor([4 5 6], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "a = np.array([1, 2, 3], dtype=np.int32)\n",
    "b = [4, 5, 6]\n",
    "\n",
    "t_a = tf.convert_to_tensor(a)\n",
    "t_b = tf.convert_to_tensor(b)\n",
    "\n",
    "print(t_a)\n",
    "print(t_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 4, 6], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(t_a.numpy()) \n",
    "c = t_a.numpy() # numpy() 로 그 넘파이 배열에 접근\n",
    "c += a # 넘파이 배열 (c = [1, 2, 3]) + (a = [1, 2, 3]) = [2, 4, 6]\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서는 행렬이다.\n",
    "텐서는 실제로는 값을 넘파이로 저장한다,\n",
    "텐서는 그 넘파이 배열의 참조를 제공한다.\n",
    "\n",
    ".numpy()를 통해서 그 참조의 실제값에 접근할수있다.\n",
    "\n",
    "텐서의 데이터 타입과 크기조작\n",
    "- tf.cast(타입을 바꿀 텐서, tf.자료형)\n",
    "  - 텐서의 데이터 타입을 원하는대로 조작가능\n",
    "- tf.reshape()\n",
    "  - 텐서의 크기를 바꾸고 차원을 추가, 제거\n",
    "- tf.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'int64'>\n",
      "(3, 5) --> (5, 3)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.] t 배열의 바뀌기 전 내용\n",
      "[[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]] t 배열이 5X6 2차원 텐서로 바뀌기 난 후 내용\n",
      "[[[[[0.]\n",
      "    [0.]\n",
      "    [0.]\n",
      "    [0.]]]\n",
      "\n",
      "\n",
      "  [[[0.]\n",
      "    [0.]\n",
      "    [0.]\n",
      "    [0.]]]]] t 배열의 바뀌기 전 내용\n",
      "[[[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]] 배열의 변환 결과\n"
     ]
    }
   ],
   "source": [
    "# - tf.cast(타입을 바꿀 텐서, tf.자료형)\n",
    "#  - 텐서의 데이터 타입을 원하는대로 조작가능\n",
    "t_a_new = tf.cast(t_a, tf.int64)\n",
    "print(t_a_new.dtype)\n",
    "\n",
    "#  텐서 전치하기\n",
    "t = tf.random.uniform(shape=(3,5))\n",
    "t_tr = tf.transpose(t)\n",
    "print(t.shape, '-->', t_tr.shape)\n",
    "\n",
    "# 텐서 크기 바꾸기 (ex rank1 -> rank2) \n",
    "t = tf.zeros((30,)) # 1X30 1차원 텐서\n",
    "print(t.numpy(), 't 배열의 바뀌기 전 내용')\n",
    "t_reshape = tf.reshape(t, shape=(5, 6))\n",
    "print(t_reshape.numpy(), 't 배열이 5X6 2차원 텐서로 바뀌기 난 후 내용')\n",
    "\n",
    "# 불필요한 차원 삭제. (크기가 1인 치원은 불필요하다.)\n",
    "t = tf.zeros((1, 2, 1, 4, 1))  # 5차원 텐서\n",
    "print(t.numpy(), 't 배열의 바뀌기 전 내용')\n",
    "t_sqz = tf.squeeze(t, axis=(2, 4)) # 3, 5번째 차원을 제거해준다.\n",
    "print(t_sqz.numpy(), '배열의 변환 결과')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그 외 전치, 원소 곱, 행렬 곱, Norm 등등의 행렬연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.27  -0.874]\n",
      " [-0.017 -0.175]\n",
      " [-0.296 -0.139]\n",
      " [-0.727  0.135]\n",
      " [-0.401  0.004]] 행렬 원소곱\n",
      "tf.Tensor([0.09  0.207], shape=(2,), dtype=float32) 열벡터들의 각각 원소 평균값 계산 결과\n",
      "tf.Tensor(\n",
      "[[-1.144  1.115 -0.87  -0.321  0.856]\n",
      " [ 0.248 -0.191  0.25  -0.064 -0.331]\n",
      " [-0.478  0.407 -0.436  0.022  0.527]\n",
      " [ 0.525 -0.234  0.741 -0.593 -1.194]\n",
      " [-0.099  0.26   0.125 -0.462 -0.396]], shape=(5, 5), dtype=float32) 행렬곱\n",
      "norm 계산\n",
      "tf.Tensor(\n",
      "[[-0.67   0.803]\n",
      " [ 0.262 -0.131]\n",
      " [-0.416  0.285]\n",
      " [ 0.952 -0.13 ]\n",
      " [ 0.32   0.21 ]], shape=(5, 2), dtype=float32)\n",
      "[1.046 0.293 0.504 0.96  0.383]\n",
      "[1.046 0.293 0.504 0.96  0.383]\n"
     ]
    }
   ],
   "source": [
    "# 텐서 간의 *원소별 곱*\n",
    "tf.random.set_seed(1)\n",
    "t1 = tf.random.uniform(shape=(5,2), minval=-1.0, maxval=1.0)\n",
    "t2 = tf.random.normal(shape=(5,2), mean=0.0, stddev=1.0)\n",
    "t3 = tf.multiply(t1, t2).numpy()\n",
    "print(t3, '행렬 원소곱')\n",
    "\n",
    "# 특정 축들을 따라 평균, 합, 표준편차를 계산\n",
    "t4 = tf.math.reduce_mean(t1, axis=0) \n",
    "# axis = 0 : 첫번째축 (열)을 기준으로 평균값 계산 -> 열벡터 평균 \n",
    "# axis = 1 :두번째축 (헹)을 기준으로 평균값 계산  -> 행벡터 평균\n",
    "# axis = none : 모든 원소의 평균값 계산\n",
    "print(t4, '열벡터들의 각각 원소 평균값 계산 결과')\n",
    "\n",
    "# 두 텐서(행렬) 간의 행렬곱\n",
    "t5 = tf.linalg.matmul(t1, t2, transpose_b=True) # t1 * t1^t 행렬곱을 계산해준다.\n",
    "print(t5, '행렬곱')\n",
    "\n",
    "# norm(크기) L^2 값 계산\n",
    "norm_t1 = tf.norm(t1, ord=2, axis=1).numpy()\n",
    "print('norm 계산')\n",
    "print(t1)\n",
    "print(norm_t1)\n",
    "print(np.sqrt(np.sum(np.square(t1), axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하나의 텐서를 여러 텐서로 나누거나, 나눠진 텐서를 하나로 붙이는 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.165 0.901 0.631 0.435 0.292 0.643]\n",
      "[array([0.165, 0.901], dtype=float32), array([0.631, 0.435], dtype=float32), array([0.292, 0.643], dtype=float32)]\n",
      "[0.165 0.901 0.631 0.435 0.292]\n",
      "[array([0.165, 0.901, 0.631], dtype=float32), array([0.435], dtype=float32), array([0.292], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# 텐서 분할 하기 -> tf.split\n",
    "# 분할 개수 지정하기\n",
    "tf.random.set_seed(1)\n",
    "t = tf.random.uniform((6, )) # 크기가 6인 균일 랜덤 원소값을 가진 텐서 생성\n",
    "print(t.numpy())\n",
    "\n",
    "t_splits = tf.split(t, num_or_size_splits=3) # 텐서를 3등분 하기.\n",
    "print([item.numpy() for item in t_splits]) # t_splits에는 나눠진 3개의 텐서가 들어있다.\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "t = tf.random.uniform((5, )) # 크기가 6인 균일 랜덤 원소값을 가진 텐서 생성\n",
    "print(t.numpy())\n",
    "\n",
    "t_splits = tf.split(t, num_or_size_splits=[3, 1, 1]) # 텐서를 3:1:1 등분하기\n",
    "print([item.numpy() for item in t_splits] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# 텐서의 결합 -> tf.concat\n",
    "# 텐서끼리의 크기가 맞지 않으면 오류가 발생함으로 주의하자.\n",
    "\n",
    "A = tf.ones((3, 1)) # 1로 채워진 1x3 크기의 텐서\n",
    "B = tf.zeros((3, 1)) # 0으로 채워진 1x2 크기의 텐서\n",
    "C = tf.concat([A, B], axis=0) # 두 텐서를 옆으로(행 방향으로) 이어붙이기\n",
    "print(C.numpy())\n",
    "C = tf.concat([A, B], axis=1) # 두 텐서를 옆으로(열 방향으로) 이어붙이기 참고로 axis=1 을 사용할려면 두 벡터가 2차원 이상이여야 한다.\n",
    "print(C.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서에서 텐서플로 데이터셋 만드는법\n",
    "\n",
    "데이터가 텐서, 넘파이, 파이썬 리스트 같은 배열과 같은 형태로 돼있을때 그 데이터를 텐서플로 데이터셋으로 만드는 과정이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리스트를 데이터셋으로 변환:\n",
      "1.2\n",
      "3.4\n",
      "7.5\n",
      "4.1\n",
      "5.0\n",
      "1.0\n",
      "\n",
      "넘파이 배열을 데이터셋으로 변환:\n",
      "1.2\n",
      "3.4\n",
      "7.5\n",
      "4.1\n",
      "5.0\n",
      "1.0\n",
      "\n",
      "텐서를 데이터셋으로 변환:\n",
      "1.2\n",
      "3.4\n",
      "7.5\n",
      "4.1\n",
      "5.0\n",
      "1.0\n",
      "\n",
      "리스트 데이터셋에서 배치로 변환:\n",
      "batch 1 [1.2 3.4 7.5]\n",
      "batch 2 [4.1 5.  1. ]\n",
      "\n",
      "넘파이 배열 데이터셋에서 배치로 변환:\n",
      "batch 1 [1.2 3.4 7.5]\n",
      "batch 2 [4.1 5.  1. ]\n",
      "\n",
      "텐서 데이터셋에서 배치로 변환:\n",
      "batch 1 [1.2 3.4 7.5]\n",
      "batch 2 [4.1 5.  1. ]\n"
     ]
    }
   ],
   "source": [
    "a = [1.2, 3.4 ,7.5, 4.1, 5.0, 1.0]\n",
    "# 리스트를 데이터셋으로 변환\n",
    "ds_list = tf.data.Dataset.from_tensor_slices(a)\n",
    "print(\"리스트를 데이터셋으로 변환:\")\n",
    "for items in ds_list:\n",
    "    print(items.numpy())\n",
    "\n",
    "# 넘파이 배열을 데이터셋으로 변환\n",
    "b = np.array([1.2, 3.4, 7.5, 4.1, 5.0, 1.0])\n",
    "ds_numpy = tf.data.Dataset.from_tensor_slices(b)\n",
    "print(\"\\n넘파이 배열을 데이터셋으로 변환:\")\n",
    "for items in ds_numpy:\n",
    "    print(items.numpy())\n",
    "\n",
    "# 텐서를 데이터셋으로 변환\n",
    "c = tf.constant([1.2, 3.4, 7.5, 4.1, 5.0, 1.0])\n",
    "ds_tensor = tf.data.Dataset.from_tensor_slices(c)\n",
    "print(\"\\n텐서를 데이터셋으로 변환:\")\n",
    "for items in ds_tensor:\n",
    "    print(items.numpy())\n",
    "\n",
    "# 데이터셋을 배치로 변환 (리스트, 넘파이, 텐서)\n",
    "batch_size = 3\n",
    "\n",
    "print(\"\\n리스트 데이터셋에서 배치로 변환:\")\n",
    "ds_list_batch = ds_list.batch(batch_size)\n",
    "for i, elem in enumerate(ds_list_batch, 1):\n",
    "    print('batch {}'.format(i), elem.numpy())\n",
    "\n",
    "print(\"\\n넘파이 배열 데이터셋에서 배치로 변환:\")\n",
    "ds_numpy_batch = ds_numpy.batch(batch_size)\n",
    "for i, elem in enumerate(ds_numpy_batch, 1):\n",
    "    print('batch {}'.format(i), elem.numpy())\n",
    "\n",
    "print(\"\\n텐서 데이터셋에서 배치로 변환:\")\n",
    "ds_tensor_batch = ds_tensor.batch(batch_size)\n",
    "for i, elem in enumerate(ds_tensor_batch, 1):\n",
    "    print('batch {}'.format(i), elem.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 개의 텐서를 하나의 데이터셋을 연결 하는법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.165 0.901 0.631]\n",
      " [0.435 0.292 0.643]\n",
      " [0.976 0.435 0.66 ]\n",
      " [0.605 0.637 0.614]], shape=(4, 3), dtype=float32)\n",
      "tf.Tensor([0 1 2 3], shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "t_x = tf.random.uniform([4, 3], dtype=tf.float32)   # 4x3 2차원 텐서\n",
    "t_y = tf.range(4)                                   # 4x1 1차원 텐서\n",
    "print(t_x)\n",
    "print(t_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " x: [0.165 0.901 0.631]  y: 0\n",
      " x: [0.435 0.292 0.643]  y: 1\n",
      " x: [0.976 0.435 0.66 ]  y: 2\n",
      " x: [0.605 0.637 0.614]  y: 3\n"
     ]
    }
   ],
   "source": [
    "# 두 텐서를 연결하여 데이터셋 만들기 (단, 두 텐서의 원소는 1:1 대응 돼야 한다.)\n",
    "\n",
    "ds_x = tf.data.Dataset.from_tensor_slices(t_x)  # 특성 데이터셋\n",
    "ds_y = tf.data.Dataset.from_tensor_slices(t_y)  # 레이블 데이터셋\n",
    "ds_joint = tf.data.Dataset.zip((ds_x, ds_y))    # 두 데이텃세을 연결\n",
    "for ex in ds_joint:\n",
    "    print(' x:', ex[0].numpy(), ' y:', ex[1].numpy()) # 첫번째 배열[0]에는 ds_x, 두번째에는 ds_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " x: [0.165 0.901 0.631]  y: 0\n",
      " x: [0.435 0.292 0.643]  y: 1\n",
      " x: [0.976 0.435 0.66 ]  y: 2\n",
      " x: [0.605 0.637 0.614]  y: 3\n"
     ]
    }
   ],
   "source": [
    "# 두 리스트를 연결하여서 데이터셋 만들기\n",
    "ds_joint = tf.data.Dataset.from_tensor_slices((t_x, t_y))    # 두 데이텃세을 연결\n",
    "for ex in ds_joint:\n",
    "    print(' x:', ex[0].numpy(), ' y:', ex[1].numpy()) # 첫번째 배열[0]에는 ds_x, 두번째에는 ds_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " x: [-0.67   0.803  0.262]  y: 0\n",
      " x: [-0.131 -0.416  0.285]  y: 1\n",
      " x: [ 0.952 -0.13   0.32 ]  y: 2\n",
      " x: [0.21  0.273 0.229]  y: 3\n"
     ]
    }
   ],
   "source": [
    "# map을 이용한 각 원소에 변환 적용\n",
    "ds_trans = ds_joint.map(lambda x,y : (x*2-1.0, y))\n",
    "for ex in ds_trans:\n",
    "    print(' x:', ex[0].numpy(), ' y:', ex[1].numpy()) # 첫번째 배열[0]에는 ds_x, 두번째에는 ds_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추후에 확률 적 경사 하강법 최적화 방식 (실시간 업데이트 방식, 개별 샘플마다 가중치를 업데이트한다.)를 사용하기 위해서는\n",
    "훈련 데이터로 무작위로 섞은 배치를 만들어 주는거이 중요하다.\n",
    "\n",
    "배치를 섞거나, 재 순환 하는 방법에 대해서 알아볼것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " x: [0.976 0.435 0.66 ]  y: 2\n",
      " x: [0.435 0.292 0.643]  y: 1\n",
      " x: [0.165 0.901 0.631]  y: 0\n",
      " x: [0.605 0.637 0.614]  y: 3\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "ds = ds_joint.shuffle(buffer_size=len(t_x)) # buffer_size : 얼마나 많은 원소를 꺼낼 것인지 결정한다.\n",
    "# buffer에 해당되는 원소는 랜덤하게 추출되고, 빈자리는 원본 데이터로 채워진다.\n",
    "# 즉 buffer_size를 원본 레이블 개수보다 작게하면, 데이터셋이 완전히 섞이지 않을수 있다.\n",
    "for ex in ds:\n",
    "    print(' x:', ex[0].numpy(), ' y:', ex[1].numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 x:\n",
      " [[0.165 0.901 0.631]\n",
      " [0.435 0.292 0.643]\n",
      " [0.976 0.435 0.66 ]]\n",
      "배치 y:\n",
      " [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# drop_remainder=False는 마지막 배치의 크기가 3보다 작아도 마지막 배치를 포함하도록 설정합니다.\n",
    "# ds는 이제 배치 단위로 묶인 데이터셋이 됩니다.\n",
    "ds = ds_joint.batch(batch_size=3, drop_remainder=False)\n",
    "\n",
    "# iter(ds)를 사용하여 배치로 묶인 데이터셋에 대한 반복자를 만듭니다.\n",
    "# next()를 사용하여 첫 번째 배치를 가져옵니다\n",
    "batch_x, batch_y = next(iter(ds))\n",
    "print('배치 x:\\n', batch_x.numpy())\n",
    "print('배치 y:\\n', batch_y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (3, 3) [0 1 2]\n",
      "1 (1, 3) [3]\n",
      "2 (3, 3) [0 1 2]\n",
      "3 (1, 3) [3]\n"
     ]
    }
   ],
   "source": [
    "# 필요한 에포크 수만큼 데이터셋을 섞어서 추출하는법\n",
    "epochs = 2\n",
    "ds = ds_joint.batch(3).repeat(count=epochs) # 데이터셋을 3개씩 나눈다. 원본 데이터는 4x3 임으로 3x3, 1x3 2개로 분할된다. 그리고 이걸 2번 반복한다. (총 4개)\n",
    "for i, (batch_x, batch_y) in enumerate(ds): # 배치의 개수는 총 4개다. (4/2) * 2\n",
    "    print(i, batch_x.shape, batch_y.numpy())\n",
    "# 4개의 배치가 출력된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (3, 3) [0 1 2]\n",
      "1 (3, 3) [3 0 1]\n",
      "2 (2, 3) [2 3]\n"
     ]
    }
   ],
   "source": [
    "# 필요한 에포크 수만큼 데이터셋을 섞어서 추출하는법\n",
    "epochs = 2\n",
    "ds = ds_joint.repeat(count=epochs).batch(3) # 데이터가 4개이고 이걸 2번 반복함으로 총 8개의 데이터가 된다, (8x3) 이걸 배치크기 3으로 분할한다. (3x3, 3x3, 2x3)\n",
    "for i, (batch_x, batch_y) in enumerate(ds): # 배치의 개수는 총 3개다\n",
    "    print(i, batch_x.shape, batch_y.numpy())\n",
    "# 3개의 배치가 출력된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " x: [0.165 0.901 0.631]  y: 0\n",
      " x: [0.435 0.292 0.643]  y: 1\n",
      " x: [0.976 0.435 0.66 ]  y: 2\n",
      " x: [0.605 0.637 0.614]  y: 3\n"
     ]
    }
   ],
   "source": [
    "for ex in ds_joint:\n",
    "    print(' x:', ex[0].numpy(), ' y:', ex[1].numpy()) # 첫번째 배열[0]에는 ds_x, 두번째에는 ds_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (2, 3) [2 1]\n",
      "1 (2, 3) [0 3]\n",
      "2 (2, 3) [0 3]\n",
      "3 (2, 3) [1 2]\n",
      "4 (2, 3) [3 0]\n",
      "5 (2, 3) [1 2]\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "epochs = 3\n",
    "# ds는 4(샘플개수)x3(샘플당 특징개수) 크기의 데이터 셋\n",
    "ds = ds_joint.shuffle(4).batch(2).repeat(count=epochs)  # 4개의 샘플을 모두 섞고, 2개의 크기로나눈다. (2, 2)총 2개 생성, 그리고 3번반복한다 -> 총6개 생성\n",
    "for i, (batch_x, batch_y) in enumerate(ds): \n",
    "    print(i, batch_x.shape, batch_y.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
